<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="An intuitive introduction to optimization algorithms like AdaGrad, RMSProp and Adam.">

<title>How Do Neural Networks Learn? – The Sigmoid Tales</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-bb49951d50c4a7e8d052f44ae1610a34.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">The Sigmoid Tales</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../posts/index.html"> 
<span class="menu-text">Posts</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#how-do-neural-networks-learn" id="toc-how-do-neural-networks-learn" class="nav-link active" data-scroll-target="#how-do-neural-networks-learn">How do Neural Networks learn?</a>
  <ul class="collapse">
  <li><a href="#gradient-descent-how-to-learn-from-mistakes" id="toc-gradient-descent-how-to-learn-from-mistakes" class="nav-link" data-scroll-target="#gradient-descent-how-to-learn-from-mistakes">Gradient descent: how to learn from mistakes</a></li>
  </ul></li>
  <li><a href="#learning-is-a-two-phase-process" id="toc-learning-is-a-two-phase-process" class="nav-link" data-scroll-target="#learning-is-a-two-phase-process">Learning is a two-phase process</a>
  <ul class="collapse">
  <li><a href="#adagrad-adaptive-gradient" id="toc-adagrad-adaptive-gradient" class="nav-link" data-scroll-target="#adagrad-adaptive-gradient">AdaGrad: Adaptive Gradient</a></li>
  <li><a href="#rmsprop" id="toc-rmsprop" class="nav-link" data-scroll-target="#rmsprop">RMSProp</a></li>
  <li><a href="#adam" id="toc-adam" class="nav-link" data-scroll-target="#adam">Adam</a></li>
  </ul></li>
  <li><a href="#comparing-the-optimizers" id="toc-comparing-the-optimizers" class="nav-link" data-scroll-target="#comparing-the-optimizers">Comparing the optimizers</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">How Do Neural Networks Learn?</h1>
  <div class="quarto-categories">
    <div class="quarto-category">optimization</div>
    <div class="quarto-category">deep learning</div>
    <div class="quarto-category">🟢beginner</div>
  </div>
  </div>

<div>
  <div class="description">
    An intuitive introduction to optimization algorithms like AdaGrad, RMSProp and Adam.
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="how-do-neural-networks-learn" class="level1">
<h1>How do Neural Networks learn?</h1>
<p>Training a neural network has never been easier. You define the architecture with <code>Keras</code> (or <code>PyTorch</code>, if you know what’s good), set the optimizer and run the <code>model.train</code> command. Many times, most people don’t pay attention to the optimizer. Most people simply choose Adam and start the training without questioning if it’s the right choice. However, as you get involved with architectures a bit more complex than the classical feed-forward neural network for the MNIST digits dataset, you may come across quite a frustrating situation: after a few epochs, the model won’t improve the loss metric. And maybe (just maybe) the reason could be the optimizer you are using.</p>
<section id="gradient-descent-how-to-learn-from-mistakes" class="level3">
<h3 class="anchored" data-anchor-id="gradient-descent-how-to-learn-from-mistakes">Gradient descent: how to learn from mistakes</h3>
<p>So, how exactly does a neural network learn from its mistakes? The answer lies in one of the simplest yet powerful ideas in optimization: <strong>gradient descent</strong>.</p>
<p>The gradient of the loss with respect to certain parameters tells us the direction in which the loss increases the most. So, to reduce the loss, we should take a small step in the opposite direction. Mathematically, we usually represent the model’s parameters with the Greek letter <span class="math inline">\(\theta\)</span>, and <span class="math inline">\(\mathcal{L}(\theta)\)</span> is the loss function. Hence, the update rule is: <span class="math display">\[
\large \theta \leftarrow \theta - \eta \cdot \nabla_{\theta} \mathcal{L}(\theta)
\]</span> Here, <span class="math inline">\(\eta\)</span> is the <strong>learning rate</strong>, a small constant which controls the step size. Repeat this process over and over, and the model will gradually adjust its parameters to reduce the error, ideally finding a minimum of the loss function. Here is a visual representation of this process:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="gradient_descent.png" class="img-fluid figure-img"></p>
<figcaption>gradient_descent</figcaption>
</figure>
</div>
<p>We usually work with really big datasets, so using all the examples is often not feasible. To solve this problem, the are a few modifications we can make to gradient descent:</p>
<ul>
<li><strong>Stochastic Gradient Descent</strong>: Instead of using all the examples in the dataset for each step, we only use one.
<ul>
<li>✔️ It is much faster than traditional gradient descent.</li>
<li>❌ It is less precise, which can hinder convergence.</li>
</ul></li>
<li><strong>Mini-batch Gradient Descent</strong>: Computes the gradient using a small subset (batch) of the dataset.
<ul>
<li>✔️ Faster than traditional gradient descent.</li>
<li>✔️ Balances precision and speed.</li>
<li>❌ Less precise than traditional gradient descent.</li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="learning-is-a-two-phase-process" class="level1">
<h1>Learning is a two-phase process</h1>
<p>The most critical hyperparameters in optimization is the <strong>learning rate</strong>. Gradient Descent and its early variants typically use a constant value for this parameter, which might seem sufficient at first glance. However, training a model can often be understood as a two-phase process: an initial phase of rapid adaptation, followed by a slower stage of fine-tuning.</p>
<p>In the early phase, the model makes several large parameter updates, as it quickly learns the general structure of the data - some sort of “heavy learning process”. Once this phase ends, the model enters a <strong>refinement stage</strong>, where more subtle adjustments are required to further improve performance. These smaller updates would require a lower learning rate, in order to avoid overshooting the minimum. We can see an example of this below:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/overshooting.png" class="img-fluid figure-img"></p>
<figcaption>overshooting</figcaption>
</figure>
</div>
<p>For this particular loss function, setting the learning rate to <code>1.01</code> would make the optimizer to overshoot, preventing convergence to the minimum. On the other hand, setting the learning rate to less than <code>1</code> would allow the optimizer to eventually find the minimum.</p>
<p>While mastering the art of selecting the right learning rate is essential, a constant learning rate can sometimes be limiting, as it lacks the flexibility to adapt to the evolving needs of the optimization process. Hence, a natural step is to design new optimizers which <strong>dynamically adjust the learning rate</strong>, either over time or based on the gradients’ behavior.</p>
<section id="adagrad-adaptive-gradient" class="level3">
<h3 class="anchored" data-anchor-id="adagrad-adaptive-gradient">AdaGrad: Adaptive Gradient</h3>
<p><strong>AdaGrad</strong>, short for <em>Adaptive Gradient</em>, was the first step towards dynamic learning rate adjustment. Instead of using a fixed learning rate, it reduces it based on the cumulative gradient of each parameter. Let’s dive into the math:</p>
<p>Suppose we use <span class="math inline">\(\theta \in \mathbb{R}^n\)</span> to denote the vector containing the <span class="math inline">\(n\)</span> parameters of the model. We will use <span class="math inline">\(g_{t}=\nabla_{\theta}\mathcal{L}(\theta_{t})\)</span> to refer to the gradient of the parameters at epoch <span class="math inline">\(t\)</span>. For a specific parameter <span class="math inline">\(\theta_{i}\)</span>, we can compute the <strong>cumulative sum of its gradients</strong> as: <span class="math display">\[
\large G_{t,i} = \sum_{\tau=1}^{t} g_{\tau,i}^2=G_{t-1,i}+g_{t,i}^{2}
\]</span> Think of <span class="math inline">\(G_{t,i}\)</span> as the <em>cumulative effort the optimizer has made during the training to update parameter <span class="math inline">\(\theta_{i}\)</span></em>. We now reformulate the update rule as follows: <span class="math display">\[
\large \theta_{t+1,i} = \theta_{t,i} - \frac{\eta}{\sqrt{G_{t,i}} + \epsilon} \cdot g_{t,i}
\]</span> If the parameter has received large or frequent updates (i.e., <span class="math inline">\(G_{t,i}\)</span> is large), the AdaGrad assumes it has already undergone substantial learning. As a result, its learning rate is reduced, allowing for more precise adjustments. This is how AdaGrad dynamically adjusts the learning rate per parameter.</p>
</section>
<section id="rmsprop" class="level3">
<h3 class="anchored" data-anchor-id="rmsprop">RMSProp</h3>
<p>Even though lowering the learning rate over time helps with the overshooting problem, AdaGrad may reduce it too quickly. In practice, if the model spends several epochs in the early stages of training, the cumulative gradients can grow large enough to shrink the effective learning rate dramatically. As a result, the model may stop learning long before reaching a satisfactory solution.</p>
<p>To avoid this. Geoffrey Hinton proposed <strong>RMSProp</strong>, a simple yet effective modification to the AdaGrad algorithm.</p>
<p>Instead of relying on the entire history of gradients, RMSProp replaces <span class="math inline">\(G_{t,i}\)</span> with an exponential moving average (EMA) of the squared gradients. RMSProp replaces the cumulative sum with: <span class="math display">\[
\large E[g^2]_{t,i}=\gamma · E[g^2]_{t-1,i}+(1-\gamma)·g^2_{t,i}
\]</span> Here, <span class="math inline">\(\gamma \in[0,1)\)</span> is the decay factor, which determines how much weight is given to past gradients. For example, if <span class="math inline">\(\gamma=0.8\)</span>, then <span class="math inline">\(E[g^2]_{t,i}\)</span> will be formed 80% by the old gradients and 20% by the new one. This way, we can control the degree to which past gradient influence the parameter update. The update rule becomes: <span class="math display">\[
\large \theta_{t+1,i} = \theta_{t,i} - \frac{\eta}{\sqrt{E[g^2]_{t,i}} + \epsilon} \cdot g_{t,i}
\]</span> This formulation ensures that parameters associated with frequently large gradients receive smaller updates, while still allowing other parameters to keep learning. Unlike AdaGrad, RMSProp avoids vanishing learning rates by gradually forgetting older information.</p>
</section>
<section id="adam" class="level3">
<h3 class="anchored" data-anchor-id="adam">Adam</h3>
<p>RMSProp solved the learning rate shrinking problem by using an exponentially decaying average of squared gradients. However, there is a subtle issue it fails to address. Imagine we have a “noisy” gradient in a non-convex zone such as: <span class="math display">\[
\large g_t \in \{-0.9,\ +1.0,\ -0.8,\ +1.1,\ \dots\}
\]</span> RMSProp would only look at the magnitude of the gradients, so <span class="math inline">\(G_t\)</span> would be: <span class="math display">\[
\large G_t \in \{+0.81,\ +1.81,\ +2.45,\ +3.66,\ \dots\}
\]</span> According to the logic of RMSProp, such a history suggests that significant updates have already been made, so it lowers the effective learning rate accordingly. However, the fact that the magnitude of the gradients are big and the signs are not consistent could be an indicator that we are not close to a minimum, but rather in a region with bumps or high-frequency noise in the loss surface. This is often the case when using mini-batches instead of the full dataset. RMSProp only uses the magnitude of the gradients, it has no way to detect this directional inconsistency.</p>
<p>This is where Adam steps in. It incorporates a running average for both the squared gradients (like RMSProp) and the gradients themselves. This way, Adam can simultaneously adapt the learning rate and track the overall direction of the descent, enabling it to perform better in noisy regions.</p>
<p>We define 4 new terms:</p>
<ul>
<li><span class="math inline">\(m_t\)</span>: exponential moving average of <span class="math inline">\(g_t\)</span></li>
<li><span class="math inline">\(v_t\)</span>: exponential moving average of <span class="math inline">\(g^2_t\)</span></li>
<li><span class="math inline">\(\beta_1, \beta_2\)</span>: decay factors</li>
</ul>
<p>Both <span class="math inline">\(m_t\)</span> and <span class="math inline">\(v_t\)</span> are updated as follows: <span class="math display">\[
\large m_t=\beta_1 ·m_{t-1} + (1-\beta_1)·g_t
\]</span> <span class="math display">\[
\large v_t=\beta_2 ·v_{t-1} + (1-\beta_2)·g^2t
\]</span></p>
<p>Since <span class="math inline">\(m_t\)</span> and <span class="math inline">\(v_t\)</span> are initialized to zero, we define: <span class="math display">\[
\large \hat{m}_t=\frac{m_t}{1-\beta_1}
\]</span> <span class="math display">\[
\large \hat{v}_t=\frac{v_t}{1-\beta_2}
\]</span></p>
<p>We are now ready to compute the update rule for Adam: <span class="math display">\[
\large \theta_{t+1}=\theta_t +\eta·\frac{\hat{m}_t}{\sqrt{\hat{v}_t}+\epsilon}
\]</span></p>
<p>This balance of directionality and adaptive learning rate makes Adam a robust choice for many modern deep learning tasks.</p>
</section>
</section>
<section id="comparing-the-optimizers" class="level1">
<h1>Comparing the optimizers</h1>
<p>Even though it is important to have a solid grasp of the theory, one must be able to quickly detect the problems when working in a real scenario. To connect theory with practice, we are going to run a simple example on a loss function.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="..\images/optimizer_animation.gif" class="img-fluid figure-img"></p>
<figcaption>animation</figcaption>
</figure>
</div>
<p>The table below summarizes the main pros and cons of each optimizer:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 8%">
<col style="width: 41%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"><strong>Optimizer</strong></th>
<th style="text-align: center;"><strong>Pros</strong></th>
<th style="text-align: center;"><strong>Cons</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">AdaGrad</td>
<td style="text-align: center;">Adapts <span class="math inline">\(\eta\)</span> for each parameter. Useful for sparse features.</td>
<td style="text-align: center;"><span class="math inline">\(\eta\)</span> can be reduced too quickly.</td>
</tr>
<tr class="even">
<td style="text-align: center;">RMSProp</td>
<td style="text-align: center;">More stable <span class="math inline">\(\eta\)</span> update than AdaGrad.</td>
<td style="text-align: center;">Doesn’t take gradient’s direction into account.</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Adam</td>
<td style="text-align: center;">Combines advantages of RMSProp and momentum.</td>
<td style="text-align: center;">May lead to overfitting. Sensitive to <span class="math inline">\(\eta\)</span> and default hyperparameters.</td>
</tr>
</tbody>
</table>
<p>In practice, no optimizer is universally best. Understanding their strengths and weaknesses is key to unlocking the model’s full potential.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>