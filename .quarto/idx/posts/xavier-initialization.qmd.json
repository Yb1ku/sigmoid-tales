{"title":"Why Neural Networks Forget","markdown":{"yaml":{"title":"Why Neural Networks Forget","description":"The Vanishing Gradient Problem Explained","format":"html","categories":["deep-learning","🟡medium"]},"headingText":"Why Neural Networks Forget: The Vanishing Gradient Problem Explained","containsRefs":false,"markdown":"\n\n\nNeural networks adjust their parameters through the well-known backpropagation algorithm. The cost function gradients are propagated from the output layer back to all layers of the model, enabling parameter updates. The network’s training depends on gradients being properly propagated. If the gradients fail to reach the earlier layers, the network won’t train as expected. Can something like this actually happen? Let’s see a practical example. \n\nConsider a layer with a sigmoid activation function. From basic calculus, we know that \n$\\large \\frac{d\\sigma(x)}{dx}=\\sigma(x)(1-\\sigma(x))$ reaches its maximum value of 0.25 at $x=0$, and is zero when $\\sigma(x)$ saturates at 0 or 1. To update the weights of this layer, we need to compute $\\large \\frac{\\partial L}{\\partial W^{(L)}}$, which by the chain rule is: \n$$ \n\\large \\frac{\\partial L}{\\partial W^{(L)}}=\\frac{\\partial z^{(L)}}{\\partial W^{(L)}}\\frac{\\partial a^{(L)}}{\\partial z^{(L)}}\\frac{\\partial L}{\\partial a^{(L)}}\n$$\nFocusing on $\\large \\frac{\\partial a^{(L)}}{\\partial z^{(L)}}$: \n$$ \n\\large \\frac{\\partial a^{(L)}}{\\partial z^{(L)}}=\\sigma(z^{(L)})(1-\\sigma(z^{L}))\n$$\nIf $\\sigma(z^{(L)})=1$ or $\\sigma(z^{(L)})=0$, then the gradient is zero. This phenomenon is called **gradient vanishing**. If there’s no gradient, there’s no learning. Since the derivative of the sigmoid is always in the range $[0,0.25]$, it's prone to vanishing gradients. \n\n# The risks of random initialization \n\nOne commonly overlooked detail when training a neural network is weight initialization. If the initial weights push the activation values into saturation zones (0 or 1), gradient vanishing can occur. For example, if weights are initialized as $W\\sim\\mathcal{N}(0,1)$, some values might lie far outside the optimal region. A natural fix might be to initialize weights as $W\\sim\\mathcal{U}[-1,1]$, keeping values within range. This may work for small, shallow networks. Let $n$ be the number of neurons in layer $l-1$, meaning the next layer has $n$ inputs. The pre-activation of a neuron is $\\sum_{i=1}^n w_{i}x_{i}$, If $n$ is large, the sum may become too large and lead to saturation. So, uniform initialization isn’t ideal either. \n\n# The Xavier Initialization solution \n\nIf initializing with zeros, Gaussian, or uniform distributions is problematic, what’s the solution? Fortunately, Xavier Glorot and Yoshua Bengio proposed one in 2010. In their paper _Understanding the Difficulty of Training Deep Feedforward Neural Networks_, they introduced what we now call **Xavier Initialization**. \n\n### Notation \n\nLet $s_{i}=z_{i}W_{i}+b_{i}$ be the pre-activation, so $z_{i+1}=f(s_{i})$. The analysis focuses near the origin, where the sigmoid behaves approximately linearly $\\sigma(x)\\approx x$ and $\\sigma'(x)\\approx 1$. The goal is to keep the variance of $z_{i+1}$ (forward pass) and the variance of gradients (backward pass) of the same order in every layer.\n\n### Forward Pass \n\nWe write $s_{i}=\\sum_{j=1}^n z_{j}^{i} w_{i}^{j}$, assuming all $w_{i}^{j}$ are independent with zero mean and variance $\\text{Var}[w_{i}]$, and similarly for $w_{j}^{i}$. Then: \n$$\n\\large \\text{Var}[s_{i}]=\\sum_{j=1}^{n_{i}}\\text{Var}[z_{i}^{j}]·\\text{Var}[w_{i}^{j}]=n_{i}·\\text{Var}[z_{i}]\\text{Var}[w_{i}]\n$$\nNear the origin, $\\large \\text{Var}[z_{i+1}]\\approx \\text{Var}[S_{i}]$, so we want: \n$$\n\\large \\mathrm{Var}[z_{i+1}] \\approx \\mathrm{Var}[z_i] \\Rightarrow n_i \\cdot \\mathrm{Var}[z_i] \\cdot \\mathrm{Var}[w_i] \\approx \\mathrm{Var}[z_i] \\Rightarrow n_i \\cdot \\mathrm{Var}[w_i] \\approx 1\n$$\n\n### Backward Pass \n\nTo compute the gradient $\\large \\delta_{i}=\\frac{\\partial L}{\\partial s_{i}}$, we use the chain rule and the linear approximation $\\large \\delta_{i} \\approx W_{i+1}^{T}\\delta_{i+1}$. Therefore: \n$$\n\\mathrm{Var}[\\delta_i] \\approx n_{i+1} \\cdot \\mathrm{Var}[W_i] \\cdot \\mathrm{Var}[\\delta_{i+1}] \\Rightarrow n_{i+1} \\cdot \\mathrm{Var}[W_i] \\approx 1\n$$\n\n### A balanced solution \n\nWe now have two desired conditions: \n\n- $n_i \\cdot \\mathrm{Var}[w_i] \\approx 1$ \n- $n_{i+1} \\cdot \\mathrm{Var}[W_i] \\approx 1$ \n\nIf $n_{i}=n_{i+1}$, both are satisfied. When not, Glorot and Bengio propose a compromise: \n$$\n\\large \\text{Var}[W_{i}]=\\frac{2}{n_{i}+n_{i+1}}\n$$\nTo implement this in practice, with a uniform distribution $W_{i}\\sim \\mathcal{U}[-a,a]$, note that: \n$$\n\\large \\frac{2}{n_i + n_{i+1}} = \\frac{a^2}{3} \\Rightarrow a = \\sqrt{\\frac{6}{n_i + n_{i+1}}}\n$$\nThis yields the final Xavier Initialization: \n$$\n\\Large W_{i}=\\mathcal{U}[-\\sqrt{\\frac{6}{n_{i}+n_{i+1}}},+\\sqrt{\\frac{6}{n_{i}+n_{i+1}}}] \n$$\n\nInitializing the parameters according to the equation above will likely solve the vanishing gradient problem. However, all this math is done assuming you have a sigmoid activation function. What about ReLU? That deserves an article for its own. \n\n---\n\n### References \n- Xavier Glorot, Yoshua Bengio, _Understanding the Difficulty of Training Deep Feedforward Neural Networks_, 2010.","srcMarkdownNoYaml":"\n\n# Why Neural Networks Forget: The Vanishing Gradient Problem Explained \n\nNeural networks adjust their parameters through the well-known backpropagation algorithm. The cost function gradients are propagated from the output layer back to all layers of the model, enabling parameter updates. The network’s training depends on gradients being properly propagated. If the gradients fail to reach the earlier layers, the network won’t train as expected. Can something like this actually happen? Let’s see a practical example. \n\nConsider a layer with a sigmoid activation function. From basic calculus, we know that \n$\\large \\frac{d\\sigma(x)}{dx}=\\sigma(x)(1-\\sigma(x))$ reaches its maximum value of 0.25 at $x=0$, and is zero when $\\sigma(x)$ saturates at 0 or 1. To update the weights of this layer, we need to compute $\\large \\frac{\\partial L}{\\partial W^{(L)}}$, which by the chain rule is: \n$$ \n\\large \\frac{\\partial L}{\\partial W^{(L)}}=\\frac{\\partial z^{(L)}}{\\partial W^{(L)}}\\frac{\\partial a^{(L)}}{\\partial z^{(L)}}\\frac{\\partial L}{\\partial a^{(L)}}\n$$\nFocusing on $\\large \\frac{\\partial a^{(L)}}{\\partial z^{(L)}}$: \n$$ \n\\large \\frac{\\partial a^{(L)}}{\\partial z^{(L)}}=\\sigma(z^{(L)})(1-\\sigma(z^{L}))\n$$\nIf $\\sigma(z^{(L)})=1$ or $\\sigma(z^{(L)})=0$, then the gradient is zero. This phenomenon is called **gradient vanishing**. If there’s no gradient, there’s no learning. Since the derivative of the sigmoid is always in the range $[0,0.25]$, it's prone to vanishing gradients. \n\n# The risks of random initialization \n\nOne commonly overlooked detail when training a neural network is weight initialization. If the initial weights push the activation values into saturation zones (0 or 1), gradient vanishing can occur. For example, if weights are initialized as $W\\sim\\mathcal{N}(0,1)$, some values might lie far outside the optimal region. A natural fix might be to initialize weights as $W\\sim\\mathcal{U}[-1,1]$, keeping values within range. This may work for small, shallow networks. Let $n$ be the number of neurons in layer $l-1$, meaning the next layer has $n$ inputs. The pre-activation of a neuron is $\\sum_{i=1}^n w_{i}x_{i}$, If $n$ is large, the sum may become too large and lead to saturation. So, uniform initialization isn’t ideal either. \n\n# The Xavier Initialization solution \n\nIf initializing with zeros, Gaussian, or uniform distributions is problematic, what’s the solution? Fortunately, Xavier Glorot and Yoshua Bengio proposed one in 2010. In their paper _Understanding the Difficulty of Training Deep Feedforward Neural Networks_, they introduced what we now call **Xavier Initialization**. \n\n### Notation \n\nLet $s_{i}=z_{i}W_{i}+b_{i}$ be the pre-activation, so $z_{i+1}=f(s_{i})$. The analysis focuses near the origin, where the sigmoid behaves approximately linearly $\\sigma(x)\\approx x$ and $\\sigma'(x)\\approx 1$. The goal is to keep the variance of $z_{i+1}$ (forward pass) and the variance of gradients (backward pass) of the same order in every layer.\n\n### Forward Pass \n\nWe write $s_{i}=\\sum_{j=1}^n z_{j}^{i} w_{i}^{j}$, assuming all $w_{i}^{j}$ are independent with zero mean and variance $\\text{Var}[w_{i}]$, and similarly for $w_{j}^{i}$. Then: \n$$\n\\large \\text{Var}[s_{i}]=\\sum_{j=1}^{n_{i}}\\text{Var}[z_{i}^{j}]·\\text{Var}[w_{i}^{j}]=n_{i}·\\text{Var}[z_{i}]\\text{Var}[w_{i}]\n$$\nNear the origin, $\\large \\text{Var}[z_{i+1}]\\approx \\text{Var}[S_{i}]$, so we want: \n$$\n\\large \\mathrm{Var}[z_{i+1}] \\approx \\mathrm{Var}[z_i] \\Rightarrow n_i \\cdot \\mathrm{Var}[z_i] \\cdot \\mathrm{Var}[w_i] \\approx \\mathrm{Var}[z_i] \\Rightarrow n_i \\cdot \\mathrm{Var}[w_i] \\approx 1\n$$\n\n### Backward Pass \n\nTo compute the gradient $\\large \\delta_{i}=\\frac{\\partial L}{\\partial s_{i}}$, we use the chain rule and the linear approximation $\\large \\delta_{i} \\approx W_{i+1}^{T}\\delta_{i+1}$. Therefore: \n$$\n\\mathrm{Var}[\\delta_i] \\approx n_{i+1} \\cdot \\mathrm{Var}[W_i] \\cdot \\mathrm{Var}[\\delta_{i+1}] \\Rightarrow n_{i+1} \\cdot \\mathrm{Var}[W_i] \\approx 1\n$$\n\n### A balanced solution \n\nWe now have two desired conditions: \n\n- $n_i \\cdot \\mathrm{Var}[w_i] \\approx 1$ \n- $n_{i+1} \\cdot \\mathrm{Var}[W_i] \\approx 1$ \n\nIf $n_{i}=n_{i+1}$, both are satisfied. When not, Glorot and Bengio propose a compromise: \n$$\n\\large \\text{Var}[W_{i}]=\\frac{2}{n_{i}+n_{i+1}}\n$$\nTo implement this in practice, with a uniform distribution $W_{i}\\sim \\mathcal{U}[-a,a]$, note that: \n$$\n\\large \\frac{2}{n_i + n_{i+1}} = \\frac{a^2}{3} \\Rightarrow a = \\sqrt{\\frac{6}{n_i + n_{i+1}}}\n$$\nThis yields the final Xavier Initialization: \n$$\n\\Large W_{i}=\\mathcal{U}[-\\sqrt{\\frac{6}{n_{i}+n_{i+1}}},+\\sqrt{\\frac{6}{n_{i}+n_{i+1}}}] \n$$\n\nInitializing the parameters according to the equation above will likely solve the vanishing gradient problem. However, all this math is done assuming you have a sigmoid activation function. What about ReLU? That deserves an article for its own. \n\n---\n\n### References \n- Xavier Glorot, Yoshua Bengio, _Understanding the Difficulty of Training Deep Feedforward Neural Networks_, 2010."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"xavier-initialization.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.31","theme":"lux","title":"Why Neural Networks Forget","description":"The Vanishing Gradient Problem Explained","categories":["deep-learning","🟡medium"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}